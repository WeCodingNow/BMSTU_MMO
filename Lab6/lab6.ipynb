{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Андреев Алексей ИУ5-23М"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для произвольного набора данных, предназначенного для классификации текстов, решите задачу классификации текста двумя способами:\n",
    "\n",
    "    Способ 1. На основе CountVectorizer или TfidfVectorizer.\n",
    "    Способ 2. На основе моделей word2vec или Glove или fastText.\n",
    "    Сравните качество полученных моделей.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bass/anaconda3/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package stopwords to /home/bass/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# 20 Newsgroups - набор состоящий из 20 тясяч постов по 20 различным темам.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "from scipy import stats\n",
    "from IPython.display import Image\n",
    "from sklearn.datasets import load_iris, load_boston\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC, OneClassSVM, SVR, NuSVR, LinearSVR\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "%matplotlib inline \n",
    "sns.set(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Вычисление метрики accuracy для каждого класса\n",
    "    y_true - истинные значения классов\n",
    "    y_pred - предсказанные значения классов\n",
    "    Возвращает словарь: ключ - метка класса, \n",
    "    значение - Accuracy для данного класса\n",
    "    \"\"\"\n",
    "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
    "    d = {'t': y_true, 'p': y_pred}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    # Метки классов\n",
    "    classes = np.unique(y_true)\n",
    "    # Результирующий словарь\n",
    "    res = dict()\n",
    "    # Перебор меток классов\n",
    "    for c in classes:\n",
    "        # отфильтруем данные, которые соответствуют \n",
    "        # текущей метке класса в истинных значениях\n",
    "        temp_data_flt = df[df['t']==c]\n",
    "        # расчет accuracy для заданной метки класса\n",
    "        temp_acc = accuracy_score(\n",
    "            temp_data_flt['t'].values, \n",
    "            temp_data_flt['p'].values)\n",
    "        # сохранение результата в словарь\n",
    "        res[c] = temp_acc\n",
    "    return res\n",
    "\n",
    "def print_accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Вывод метрики accuracy для каждого класса\n",
    "    \"\"\"\n",
    "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
    "    if len(accs)>0:\n",
    "        print('Метка \\t Accuracy')\n",
    "    for i in accs:\n",
    "        print('{} \\t {}'.format(i, accs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"comp.os.ms-windows.misc\", \"sci.crypt\", \"talk.religion.misc\", \"rec.autos\"]\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
    "data = newsgroups['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество сформированных признаков - 63878\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer\n",
    "vocabVect = CountVectorizer()\n",
    "vocabVect.fit(data)\n",
    "corpusVocab = vocabVect.vocabulary_\n",
    "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pp=46599\n",
      "cbnewsl=19077\n",
      "cb=19041\n",
      "att=15577\n",
      "com=20266\n",
      "peter=45744\n",
      "peng=45600\n",
      "subject=54145\n",
      "1990=2697\n"
     ]
    }
   ],
   "source": [
    "for i in list(corpusVocab)[1:10]:\n",
    "    print('{}={}'.format(i, corpusVocab[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2157x63878 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 381088 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = vocabVect.transform(data)\n",
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63878"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размер нулевой строки\n",
    "len(test_features.todense()[0].getA1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bass/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/bass/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/bass/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '00000000': 2, '00000000b': 3,\n",
      "                            '00000001': 4, '00000001b': 5, '00000010': 6,\n",
      "                            '00000010b': 7, '00000011': 8, '00000011b': 9,\n",
      "                            '00000100': 10, '00000100b': 11, '00000101': 12,\n",
      "                            '00000101b': 13, '00000110': 14, '00000110b': 15,\n",
      "                            '00000111': 16, '00000111b': 17, '00001000': 18,\n",
      "                            '00001000b': 19, '00001001': 20, '00001001b': 21,\n",
      "                            '00001010': 22, '00001010b': 23, '00001011': 24,\n",
      "                            '00001011b': 25, '00001100': 26, '00001100b': 27,\n",
      "                            '00001101': 28, '00001101b': 29, ...})\n",
      "Модель для классификации - LogisticRegression(C=3.0)\n",
      "Accuracy = 0.956884561891516\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bass/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '00000000': 2, '00000000b': 3,\n",
      "                            '00000001': 4, '00000001b': 5, '00000010': 6,\n",
      "                            '00000010b': 7, '00000011': 8, '00000011b': 9,\n",
      "                            '00000100': 10, '00000100b': 11, '00000101': 12,\n",
      "                            '00000101b': 13, '00000110': 14, '00000110b': 15,\n",
      "                            '00000111': 16, '00000111b': 17, '00001000': 18,\n",
      "                            '00001000b': 19, '00001001': 20, '00001001b': 21,\n",
      "                            '00001010': 22, '00001010b': 23, '00001011': 24,\n",
      "                            '00001011b': 25, '00001100': 26, '00001100b': 27,\n",
      "                            '00001101': 28, '00001101b': 29, ...})\n",
      "Модель для классификации - LinearSVC()\n",
      "Accuracy = 0.9601298099211869\n",
      "===========================\n",
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '00000000': 2, '00000000b': 3,\n",
      "                            '00000001': 4, '00000001b': 5, '00000010': 6,\n",
      "                            '00000010b': 7, '00000011': 8, '00000011b': 9,\n",
      "                            '00000100': 10, '00000100b': 11, '00000101': 12,\n",
      "                            '00000101b': 13, '00000110': 14, '00000110b': 15,\n",
      "                            '00000111': 16, '00000111b': 17, '00001000': 18,\n",
      "                            '00001000b': 19, '00001001': 20, '00001001b': 21,\n",
      "                            '00001010': 22, '00001010b': 23, '00001011': 24,\n",
      "                            '00001011b': 25, '00001100': 26, '00001100b': 27,\n",
      "                            '00001101': 28, '00001101b': 29, ...})\n",
      "Модель для классификации - KNeighborsClassifier()\n",
      "Accuracy = 0.7148817802503477\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '000': 1, '00000000': 2, '00000000b': 3,\n",
      "                            '00000001': 4, '00000001b': 5, '00000010': 6,\n",
      "                            '00000010b': 7, '00000011': 8, '00000011b': 9,\n",
      "                            '00000100': 10, '00000100b': 11, '00000101': 12,\n",
      "                            '00000101b': 13, '00000110': 14, '00000110b': 15,\n",
      "                            '00000111': 16, '00000111b': 17, '00001000': 18,\n",
      "                            '00001000b': 19, '00001001': 20, '00001001b': 21,\n",
      "                            '00001010': 22, '00001010b': 23, '00001011': 24,\n",
      "                            '00001011b': 25, '00001100': 26, '00001100b': 27,\n",
      "                            '00001101': 28, '00001101b': 29, ...})\n",
      "Модель для классификации - LogisticRegression(C=3.0)\n",
      "Accuracy = 0.9643022716736208\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '000': 1, '00000000': 2, '00000000b': 3,\n",
      "                            '00000001': 4, '00000001b': 5, '00000010': 6,\n",
      "                            '00000010b': 7, '00000011': 8, '00000011b': 9,\n",
      "                            '00000100': 10, '00000100b': 11, '00000101': 12,\n",
      "                            '00000101b': 13, '00000110': 14, '00000110b': 15,\n",
      "                            '00000111': 16, '00000111b': 17, '00001000': 18,\n",
      "                            '00001000b': 19, '00001001': 20, '00001001b': 21,\n",
      "                            '00001010': 22, '00001010b': 23, '00001011': 24,\n",
      "                            '00001011b': 25, '00001100': 26, '00001100b': 27,\n",
      "                            '00001101': 28, '00001101b': 29, ...})\n",
      "Модель для классификации - LinearSVC()\n",
      "Accuracy = 0.9786740843764488\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '000': 1, '00000000': 2, '00000000b': 3,\n",
      "                            '00000001': 4, '00000001b': 5, '00000010': 6,\n",
      "                            '00000010b': 7, '00000011': 8, '00000011b': 9,\n",
      "                            '00000100': 10, '00000100b': 11, '00000101': 12,\n",
      "                            '00000101b': 13, '00000110': 14, '00000110b': 15,\n",
      "                            '00000111': 16, '00000111b': 17, '00001000': 18,\n",
      "                            '00001000b': 19, '00001001': 20, '00001001b': 21,\n",
      "                            '00001010': 22, '00001010b': 23, '00001011': 24,\n",
      "                            '00001011b': 25, '00001100': 26, '00001100b': 27,\n",
      "                            '00001101': 28, '00001101b': 29, ...})\n",
      "Модель для классификации - KNeighborsClassifier()\n",
      "Accuracy = 0.9119146963375059\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
    "    for v in vectorizers_list:\n",
    "        for c in classifiers_list:\n",
    "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
    "            score = cross_val_score(pipeline1, newsgroups['data'], newsgroups['target'], scoring='accuracy', cv=3).mean()\n",
    "            print('Векторизация - {}'.format(v))\n",
    "            print('Модель для классификации - {}'.format(c))\n",
    "            print('Accuracy = {}'.format(score))\n",
    "            print('===========================')\n",
    "\n",
    "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab), TfidfVectorizer(vocabulary = corpusVocab)]\n",
    "classifiers_list = [LogisticRegression(C=3.0), LinearSVC(), KNeighborsClassifier()]\n",
    "VectorizeAndClassify(vectorizers_list, classifiers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['pp',\n",
       "  'cbnewsl',\n",
       "  'cb',\n",
       "  'att',\n",
       "  'com',\n",
       "  'peter',\n",
       "  'peng',\n",
       "  'subject',\n",
       "  'integra',\n",
       "  'ls',\n",
       "  'sale',\n",
       "  'organization',\n",
       "  'bell',\n",
       "  'laboratories',\n",
       "  'distribution',\n",
       "  'nj',\n",
       "  'keywords',\n",
       "  'sale',\n",
       "  'integra',\n",
       "  'lines',\n",
       "  'integra',\n",
       "  'ls',\n",
       "  'sale',\n",
       "  'speed',\n",
       "  'sunroof',\n",
       "  'rear',\n",
       "  'spoiler',\n",
       "  'new',\n",
       "  'tires',\n",
       "  'k',\n",
       "  'miles',\n",
       "  'best',\n",
       "  'offer',\n",
       "  'call',\n",
       "  'email',\n",
       "  'att',\n",
       "  'hotsoup',\n",
       "  'peng']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word2vec \n",
    "# Подготовим корпус\n",
    "corpus = []\n",
    "stop_words = stopwords.words('english')\n",
    "tok = WordPunctTokenizer()\n",
    "for line in newsgroups['data']:\n",
    "    line1 = line.strip().lower()\n",
    "    line1 = re.sub(\"[^a-zA-Z]\",\" \", line1)\n",
    "    text_tok = tok.tokenize(line1)\n",
    "    text_tok1 = [w for w in text_tok if not w in stop_words]\n",
    "    corpus.append(text_tok1)\n",
    "    \n",
    "corpus[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(v, c):\n",
    "    model = Pipeline(\n",
    "        [(\"vectorizer\", v), \n",
    "         (\"classifier\", c)])\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print_accuracy_score_for_classes(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingVectorizer(object):\n",
    "    '''\n",
    "    Для текста усредним вектора входящих в него слов\n",
    "    '''\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.size = model.vector_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([np.mean(\n",
    "            [self.model[w] for w in words if w in self.model] \n",
    "            or [np.zeros(self.size)], axis=0)\n",
    "            for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bass/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "0 \t 0.921760391198044\n",
      "1 \t 0.8916256157635468\n",
      "2 \t 0.9451697127937336\n",
      "3 \t 0.8687258687258688\n"
     ]
    }
   ],
   "source": [
    "# Обучающая и тестовая выборки\n",
    "\n",
    "model_data = word2vec.Word2Vec(corpus, workers=4, min_count=10, window=10, sample=1e-3)\n",
    "\n",
    "boundary = 700\n",
    "X_train = corpus[:boundary] \n",
    "X_test = corpus[boundary:]\n",
    "y_train = newsgroups['target'][:boundary]\n",
    "y_test = newsgroups['target'][boundary:]\n",
    "\n",
    "sentiment(EmbeddingVectorizer(model_data.wv), LogisticRegression(C=5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
